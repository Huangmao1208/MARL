queue_app 
ac_policy: {'a': 8, 'epsilon_bar': 0.1, 'lr_actor': 0.0002, 'b': 2.5, 'l1_out_l2_in_actor': 16, 'l1_out_l2_in_critic': 16, 'recovery_cost': 27}
q_learning: {'a': 4, 'epsilon_bar': 0.01, 'l1_out_l2_in_q': 32, 'lr_q': 2e-05, 'recovery_cost': 11}

markov_app
ac_policy: {'a': 4, 'epsilon_bar': 0.1, 'lr_actor': 0.0005, 'b': 3.0, 'l1_out_l2_in_actor': 32, 'l1_out_l2_in_critic': 64, 'recovery_cost': 14}
q_learning: {'a': 4, 'epsilon_bar': 1, 'l1_out_l2_in_q': 16, 'lr_q': 2e-05, 'recovery_cost': 28}

uniform_app
ac_policy: {'a': 6, 'epsilon_bar': 0.1, 'lr_actor': 0.0003, 'b': 2.0, 'l1_out_l2_in_actor': 16, 'l1_out_l2_in_critic': 16, 'recovery_cost': 24}
q_learning: {'a': 6, 'epsilon_bar': 0.01, 'l1_out_l2_in_q': 32, 'lr_q': 8e-05, 'recovery_cost': 12}

normal_app
ac_policy: {'a': 2, 'epsilon_bar': 1, 'lr_actor': 0.0005, 'b': 1.5, 'l1_out_l2_in_actor': 32, 'l1_out_l2_in_critic': 8, 'recovery_cost': 28}
q_learning: {'a': 8, 'epsilon_bar': 0.1, 'l1_out_l2_in_q': 32, 'lr_q': 0.0005, 'recovery_cost': 21}